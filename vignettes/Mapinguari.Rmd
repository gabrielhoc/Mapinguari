---
title: "Mapinguari"
author: "Gabriel Caetano, Juan Santos, Barry Sinervo"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Mapinguari}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Mapinguari is an add-on package for program R, aimed at providing tools to facilitate the incorporation of biological processes in biogeographical analyses. It offers conveniences in fitting and comparing physiological models, as well as spatially extrapolating those models. The functions to model physiology offer enough flexibility to account for plasticity in physiology and microclimatic variation in the extrapolation. The package also allows to estimate geographical variation in the duration of phenological events, and summarize spatial data during these events. The spatial information generated using physiological and phenological models can then be used as predictors in species distribution modelling, for which Mapinguari offers tools for adequate evaluation, consensus, plotting and comparision, as well as utilities to deal with common pitfalls such as auto correlation in occurrence records and colinearity in spatial predictors.
	
It is well documented that climate change has severe effects on biodiversity. Species distribution modeling or SDM is a popular tool to predict individual species distributions and project the effects of these under diverse climate change models. Most SDMs are correlative and do not take into account biological processes underlying species responses to environmental variables. We aim to provide a modeling tool to fulfill this gap by estimating geographical layers with biologically relevant information that can be used in SDMs or other biogeographical analysis, as well as providing convenience and stimulating good practices for predictor selection and plotting. 

Mapinguari offers functions that facilitate the spatial extrapolation of models relating physiological measures of organisms, such as locomotor performance, metabolic and developmental rates or duration of activity to available spatialized information, such as climatic or geological variables. Those extrapolated values might function as an approximation of how well the organismâ€™s body works under those conditions, and therefore, might be relevant for informing about the species distribution under current and future conditions, specially climate, which is expected to change drastically in the near future, potentially affecting the ability of organisms to inhabit certain regions. This ecophysiological projections can be informative by themselves, but also complement traditional correlative methods.
		 
The timing and duration of specific events in the life of an organism can be crucial for its existence, such as breeding, flowering, fruiting or hibernating seasons. During those seasons, some organisms might become specially vulnerable to external conditions, which means the conditions during those times can be more informative of the ability of the organisms to remain in an area. Some of those events happen periodically and predictably, determined either by cycles inherent to the organism or by external inffluences. Mapinguari offers tools to predict the timing and duration of those events under different conditions, as well as gathering information about these and other conditions during those times. This feature can be combined with the physiological extrapolations, allowing further complexity in modelling.

The package is currently hosted on GitHub, this is how to install and load it:

```{r, message = FALSE, warning = FALSE}
# You need package devtools to install packages from GitHub
# library(devtools)

#install_github("gabrielhoc/Mapinguari")
devtools::load_all(".")

#library(Mapinguari)
```

Next, we are going to give an example of how to use the package, using some simulated data:

# The fate of *Fulanus*

*Fulanus beltranus* is a fictional species of lizard from Democratic Republic of Congo. We would like to find out how this species is going to do in different climate change scenarios. First let's look at the points where it is currently known to occurr. To access the table with distribution data `FulanusDistribution`, package Mapinguari has to be loaded. Here we use ggmap to plot the points over a image from Google Maps (copyright Google).

```{r, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 6, eval = FALSE}
#library(Mapinguari)

# Load ggmap and ggplot2 to make the map
library(ggmap)
library(ggplot2)

Fulanus_bbox <- make_bbox(lat = Lat, 
  lon = Lon, 
  data = FulanusDistribution,
  f = 0.2)

Fulanus_big <- get_map(location = Fulanus_bbox, 
  source = "google", 
  maptype = "terrain")

ggmap(Fulanus_big) +
  geom_point(data = FulanusDistribution, 
    mapping = aes(x = Lon, y = Lat), 
    size = 1, 
    colour = 'red')
```

First, let's get some information on the climate of this region.

## Obtaining rasters

How does the climate looks like in this area? We can use function `get_rasters` to extract WorldClim surfaces for that area. The argument `ext` tells us which is the area you desire to crop your rasters around. It accepts either a numerical vector with the coordinates of cropping limits (in order: western most longitude, easter most longitude, southern most latitude then northern most latitude), or a table of longitudes and latitudes, in which case it will grab the coordinates of the most extreme points and use those as the cropping limits. The argument `margin` adds to these limits, and it is on the same unit as the coordinates you supply.

```{r, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 6}
# library(Mapinguari)
library(raster)

FulanusEcoRasters_present <-
   get_rasters(
     raster_source = "/Users/gabriel/Documents/Mapinguari/global_grids_10_minutes",
     ext = FulanusDistribution,
     margin = 5,
     non_fixed_var = c('prec', 'tmin', 'tmax'),
     fixed_var = 'alt',
     years = c("present"),
     reorder = TRUE)

plot(FulanusEcoRasters_present[[1]])
```

`get_rasters` is able to download rasters from WorldClim if you leave `raster_source` blank, but you probably don't want to download them every time you are executing the function. That's why the argument `raster_source` will also take a list of rasters from your workspace or a path to a folder containing those rasters. These options also have the advantage of being able to input any raster you want, not being limited to the ones you can download from WorldClim.

However, in order for Mapinguari to recognize which variables correspond to each year or scenario, you have to name your folders and list elements following the convention *variable_year_scenario*. The default character for separating those terms is "_", but you can change that, as long as you do the corresponding change to the argument `separator` in the function. Some of your rasters will not be subject to scenarios, since they are measures of current climate, instead of projections. In that case you only have to name them *variable_year*, omitting the scenario term. The argument `baseline` identifies which years are not subject to scenarios. The default for this argument is `present`, but it can be changed at your convenience. Some other variables are constant accross time, such as altitude. In that case you only have to write the name of the variable. Here is an example of how my folder is structured:

![](/Users/gabriel/Documents/Mapinguari/vignettes/folder_organization.png)

I'm going to assign the path to that directory to an object:

```{r}
my_directory <- "/Users/gabriel/Documents/Mapinguari/global_grids_10_minutes"
```

Why did I place some variables in the `non-fixed` argument and others in the `fixed` argument? Well, that will become relevant once we start making future projections. Variables on `non_fixed` are things such as climate, which you expect to change in different times and future scenarios, while variables in `fixed` are things such as geological features, which you expect to remain constant accross the time projected.

Another important argument for non-fixed variables is `reorder`, which will take the last two characters of your RasterLayer names, replace letters with zeros and order the layers in ascending order of those numbers. This is useful because of the way some of the WorldClim layers are named when you download them, which when stacked will be placed out of chronological order. This argument fixes that. But be careful if you are using layers with different names than the ones from WorldClim. If they are in the correct order when you stack them, `reorder` could scramble them, so set it to FALSE.

Let's try doing some projections for the future years of 2050 and 2070:

```{r, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 6}
FulanusEcoRasters_future <-
   get_rasters(
     raster_source = my_directory,
     ext = FulanusDistribution,
     margin = 5,
     non_fixed_var = c('prec', 'tmin', 'tmax'),
     years = c('2050', '2070'),
     scenarios = c('rcp26', 'rcp45', 'rcp85'),
     reorder = TRUE)

plot(FulanusEcoRasters_future$`2050_rcp26`)
```

As you can see, we have multiple rasters for each variable, one for each month. When doing biogeographical analysis, such as species distribution models, it is common to need a summary raster for each variable, such as the annual average or total. Function `transform_rasters` can help us to get summaries for the whole year or for parts of the year.

## Summarizing time-varying rasters

Function `transform_rasters` allows us to apply any vectorized function to any subset of rasters for each variable, so we can get measures like averages, standard deviations, totals, variance or any other summary function for the month layers. Summaries have the advantage of reducing computation time, as they allows us to work with less layers. The first argument is `raster_stack`, which is where we supply the RasterStack with the layers for the calculations. The second argument, `FUN_qlist`, is where we supply the functions to be applied, the variables to apply the functions to, as well as the subset of the layers for that variable that will be included in the calculation. This expressions have to be inside a `qlist`, which is a list that returns its arguments unevaluated. In order for the function to find the layers, the layer names must begin with the same variable name used in the `FUN_qlist` expressions, before the separator character, which can be specified in argument `separator` (default is "_").

```{r, fig.height = 6, fig.width = 6}

Fulanus_present_year_summaries <-
   transform_rasters(FulanusEcoRasters_present$present,
    FUN_qlist = qlist(tmax_average_year = mean(tmax),
                      tmax_sd_year = sd(tmax), 
                      tmin_average_year = mean(tmin),
                      tmin_sd_year = sd(tmin),
                      prec_total_year = sum(prec)))

# The function operates in RasterStacks, if you want to apply it to a list, you can use `lapply`:

Fulanus_future_year_summaries <-   
lapply(FulanusEcoRasters_future, transform_rasters,
    FUN_qlist = qlist(tmax_average_year = mean(tmax),
                      tmax_sd_year = sd(tmax)))

# You can also specify different subsets of the year to get, for example, summaries for seasons of the year, by using double square brackets.

Fulanus_present_two_seasons_summaries <-
   transform_rasters(FulanusEcoRasters_present$present,
    FUN_qlist = qlist(tmax_average_breeding = mean(tmax[[3:8]]),
                      tmax_average_growing = sd(tmax[[c(7:12, 1:3)]])))

plot(Fulanus_present_year_summaries$tmax_average_year)
plot(Fulanus_present_two_seasons_summaries$tmax_average_breeding)
plot(Fulanus_present_two_seasons_summaries$tmax_average_growing)
```

Summary functions are an useful example, but we can apply more complex functions, such as models using the spatial variables you have to create new variables. But before we create those layers, we must fit the models in question. Function `fit_curves` allows us to fit models, compare them and get a vectorized function which returns the prediction of the model given the necessary variables.

## Fitting physiological models

Function `fit_curves` main goal is to create functions that give us the relationship between a biological measure and a environmental one. It outputs vectorized functions that are able to give us the model prediction for any value inputed, so the biological measures can be extrapolated to other environmental data, such as spatial or temporal data. It also evaluates the models, allowing the users to compare different parameterizations or specifications. The user only needs to inform a list of models in argument `models` and the function will output a table with their AIC, BIC, log likelihood, delta AIC, delta BIC and a rank for AIC and BIC values. more important, the function will create a vectorized predict function for each model, which can be used to get model predictions for new data, and can be used in `transform_models` to spatially extrapolate the model.

Back to *Fulanus*, we measured the maximum running speed of several individuals under different temperatures. We also recorded their body sizes, since that is a variable that is very likely to inffluence their performance. Here is how the data look like:

```{r}
head(FulanusPhysiology)
```

Note that we also attributed a number to each lizard to keep track of which lizard did which trial. That is important because, since the same lizard ran different trials, the data points are not independent and we have to account for that when building our model.

Argument `models` can be a single model or a list of models. In this case we are fitting GAMM models, which can account for the autocorrelation from running several tests with each individual. You can name the models by putting their names on the list. Most model functions that have a method for function `predict` should work.

```{r}
library(mgcv)

# Here is an example without naming the models. They will be assigned a generic name.
perf_functions_no_name <-
  fit_curves(gamm(performance ~ s(temp, bs = 'cs') + size, 
                  random = list(id = ~ 1), 
                  data = FulanusPhysiology))

# It is easier to keep track if you name them something meaningful (TPC means thermal performance curve). Also, you can fit multiple models at the same time.
perf_functions <-
  fit_curves(list(tpc_gamm_size = gamm(performance ~ s(temp, bs = 'cs') + size, 
                                       random = list(id = ~ 1), 
                                       data = FulanusPhysiology),
                  tpc_gamm_no_size = gamm(performance ~ s(temp, bs = 'cs'), 
                                          random = list(id = ~ 1), 
                                          data = FulanusPhysiology)))
```

The function prints a table containing statistics on each model, for comparison, and outputs a list containing that table, as well as a sub list for each model, containing the predictor function, raw model output and inputed arguments. You can assign the predictor function to a name, which can be applied to any value.

```{r}
perf_functions$stats

perf_functions$tpc_gamm_size$predict
perf_functions$tpc_gamm_size$model
perf_functions$tpc_gamm_size$output

my_tpc <- perf_functions$tpc_gamm_size$predict

my_tpc(temp = 20, size = 3)
my_tpc(temp = 20:40, size = 3)
```

The predictor function can be combined with the output from `transform_rasters` to spatialize the variable on the right hand side of the model formula, as long as you have rasters for the variables on the left hand side. On the next section we are going to give an example

## Spatialize a physiological model

`transform_rasters` can do the link between your physiological model and your spatial environmental data. The predictor functions obtained in `fit_curves` can be used in the same way we used the summary functions in the previous examples. This interface also allows us to set values for terms in the model, such as estimating performance for animals of specific sizes, in the thermal performance model we fitted before.

Note, however, that the variables on the rasters used have to be on the same scale as the data you used to fit the models. In this case, the raster temperatures are multiplied by 10, so we have to fix that first.

```{r, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 6}

# Let's scale the tmin and tmax average layers
FulanusEcoRasters_present_temps <- Fulanus_present_year_summaries[[c(1,3)]]/10

# You can calculate the performance for minimum and maximum temperatures, by changing the term on the expression inside FUN_qlist

Perf_rasters_tmax <-
  transform_rasters(raster_stack = FulanusEcoRasters_present_temps,
                    FUN_qlist = qlist(perf_tmax = my_tpc(tmax, 
                                                         size = mean(FulanusPhysiology$size))))

Perf_rasters_tmin <-
  transform_rasters(raster_stack = FulanusEcoRasters_present_temps,
                    FUN_qlist = qlist(perf_tmin = my_tpc(tmin, 
                                                         size = mean(FulanusPhysiology$size))))

# We can get the performance for individuals of different ages by changing the `size` argument on the my_tpc function (lizard's age is highly correlated with size)

Perf_rasters_young <-
  transform_rasters(raster_stack = FulanusEcoRasters_present_temps,
                    FUN_qlist = qlist(perf_young = my_tpc(tmax, 
                                                          size = min(FulanusPhysiology$size))))

Perf_rasters_old <-
  transform_rasters(raster_stack = FulanusEcoRasters_present_temps,
                    FUN_qlist = qlist(perf_old = my_tpc(tmax, 
                                                        size = max(FulanusPhysiology$size))))

plot(Perf_rasters_tmax$perf_tmax)
plot(Perf_rasters_tmin$perf_tmin)
plot(Perf_rasters_young$perf_young)
plot(Perf_rasters_old$perf_old)
```

The function operates in RasterStacks, if you want to apply it to a list, you can use `lapply`:

```{r, eval, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 6, eval = FALSE}
FulanusEcoRasters_future_temps <- lapply(Fulanus_future_year_summaries, function(x) x[[2:4]]/10)

Perf_rasters_list <- lapply(FulanusEcoRasters_future_temps, transform_rasters,
  FUN_qlist = qlist(perf_tmin = my_tpc(tmin, 
                                       size = mean(FulanusPhysiology$size)))
)
```

## Summarizing accross spatially varying periods (geographical variation in phenology)

Now, let's say the most crucial period for *Fulanus* population dynamics is their breeding period and they wil breed only under certain climatic conditions. This might cause their breeding period to vary spatially and temporally. In order to account for that, we can fit a logistic model of breeding status vs climate, using data from the table `FulanusBreeding`, which contain data on breeding status and climate at different localities. Then we can use this model to create binary rasters with the locations where Fulanus is breeding at each month, using function `transform_rasters`. After that, we can use the rasters generated as weights to average other variables. 

```{r, fig.height = 6, fig.width = 6}

Phen_model <- fit_curves(models = glm(breeding ~ prec, family = binomial(link = 'logit'), data = FulanusBreeding))

PhenFUN1 <- Phen_model$model_1$predict

season_rain_rasters <-
  transform_rasters(raster_stack = FulanusEcoRasters_present$present,
                    FUN_qlist = qlist(season_rain = PhenFUN1(prec)))

# Let's convert the raster to binary

season_rain_rasters_binary <-
  calc(season_rain_rasters, function(x) ifelse(x < 0.5, 0, 1))

FulanusEcoRasters_season_rain <-
    transform_rasters(FulanusEcoRasters_present$present,
      FUN_qlist = qlist(weighted.mean(tmax, weights = season_rain_rasters_binary)))

# Length of Breeding season
plot(sum(season_rain_rasters))

# Average Performance during breeding season
plot(FulanusEcoRasters_season_rain$weighted.mean_tmax_season_rain_rasters_binary)
```

The function can also be a condition. Let's say we are only interested on the periods when precipitation is bigger than 150.

```{r, fig.height = 6, fig.width = 6}

PhenFUN2 <- function(x) ifelse(x > 150, 1, 0)

season_prec_rasters <-
  transform_rasters(raster_stack = FulanusEcoRasters_present$present,
    FUN_qlist = qlist(season_rain = PhenFUN2(prec)))

FulanusEcoRasters_season_prec <-
    transform_rasters(FulanusEcoRasters_present$present,
      FUN_qlist = qlist(weighted.mean(tmax, weights = season_rain_rasters_binary)))

# Length of Breeding season
plot(sum(season_prec_rasters))

# Average Performance during breeding season
plot(FulanusEcoRasters_season_prec)

```

# Part under development

## An integrative example, calculating hours of activity

*Describe data set

Steps:
-get EVI or NDVI rasters for the future (They are based in satellite images, so it might not be possible, if it isn't, use AET or CWD instead)
-Get EVI values for the coordinates of the locations in the table `FulanusMicroclimate` and add values to the table;
-Use `fit_curves` to make a model like `HA ~ temp + EVI` from `FulanusMicroclimate`;
-Use `transform_rasters` again to extrapolate HA.

```{r}
head(FulanusMicroclimate)
```


```{r, fig.height = 6, fig.width = 6}
# Summarise microclimate table by day
#make this into a function

library(dplyr)

# Fulanus only has activity on microhabitats between 21 and 33 degrees celsius

FulanusMicroclimate$HA <- ifelse(FulanusMicroclimate$temp > 16 & FulanusMicroclimate$temp < 28, 1, 0)

# make safe check to see if every day is on the same temporal resolution

resolution_minutes <- 4

microclimate_by_day <- 
group_by(FulanusMicroclimate, day, month, year) %>% 
summarise(HA = sum(HA)/60/resolution_minutes,
          temp_micro_avg = mean(temp),
          temp_air_avg = mean(t_air),
          Lon = unique(Lon), 
          Lat = unique(Lat))

# try to do with FlexParamCurve, instead of nls
# for nls, we have to specify the formal arguments of the predict function, because the formula is weird

HA_curve <- 
fit_curves(nls(HA ~ SSlogis(temp_air_avg, Asym, xmid, scal), data = microclimate_by_day), 
  predict_formals = "temp")

HA_curve$model_1$predict

# Let's try also including EVI
# I don't have a EVI surface right now, so let's pretend this is it 
EVI_present <- FulanusEcoRasters_present$present$prec_1

# let's include a new column in the table with EVI
library(raster)
microclimate_by_day$EVI <- extract(EVI_present, data.frame(Lon = microclimate_by_day$Lon, Lat = microclimate_by_day$Lat))

# Let's try fitting a curve with EVI

HA_EVI_curve <- 
fit_curves(nls(HA ~ SSlogis(temp_air_avg + EVI, Asym, xmid, scal), data = microclimate_by_day), 
  predict_formals = c("temp", "EVI"))

HAlogis <- HA_EVI_curve$model_1$predict

# get necessary variables (it should be EVI instead of prec, I'm using it as a placeholder)

Fulanus_present_year_averages <-
   transform_rasters(FulanusEcoRasters_present$present,
    FUN_qlist = qlist(tmax_average = mean(tmax),
                      prec_average = mean(prec)))

HA_raster_present <-
  transform_rasters(raster_stack = Fulanus_present_year_averages,
    FUN_qlist = qlist(HA = HAlogis(tmax, prec))) # 'prec' is here as a placeholder, get real EVI

plot(HA_raster_present)
```

## get performace considering microhabitat temperatures

We used WorldClim temperatures to estimate performance accross the distribution of our species. Those temperatures are more akin to those measured at weather station. A more precise way to do it might be using estimates of microhabitat temperature. We have microhabitat temperatures from our `FulanusMicroclimate` dataset, which we can use to create a model relating microhabitat temperature to air temperature and vegetation and extrapolate it (I'm at the field with limited internet, so I don't have a proper vegetation layer, such as EVI or NDVI, but I will use precipitation as a placeholder and fix it later).

```{r, fig.height = 6, fig.width = 6}

microtemp_model <-
fit_curves(glm(temp_micro_avg ~ temp_air_avg + EVI, data = microclimate_by_day))

predict_microtemp <- microtemp_model$model_1$predict

#first, let's fix the temperature scale
Fulanus_present_year_averages_scaled <- Fulanus_present_year_averages
Fulanus_present_year_averages_scaled$tmax_average <- Fulanus_present_year_averages$tmax_average/10

microtemp_raster_present <-
  transform_rasters(raster_stack = Fulanus_present_year_averages,
    FUN_qlist = qlist(microtemp = predict_microtemp(tmax, prec))) # 'prec' is here as a placeholder, get real EVI

Perf_rasters_microtemp <-
  transform_rasters(raster_stack = microtemp_raster_present,
                    FUN_qlist = qlist(perf_microtemp = my_tpc(microtemp, 
                                                              size = mean(FulanusPhysiology$size))))

plot(Perf_rasters_microtemp)
```

## Creating a function for the Sinervo method for hours of activity

Sometimes, you might want to create a function to use in `transform_rasters` that is not a prediction of a model you can fit with `fit_curves`. `transform_rasters` will take custom functions you make if they are vectorized. There are different ways to vectorize a function, like function `Vectorize`. We are going to make an example function, the Sinervo method for calculating hours of activity (Sinervo 2010), and use it to create a raster of hours of activity. This method creates a sin wave between the minimum and maximum temperatures for a location, simulating daily temperature variation, then counts how much time the temperatures are between the thresholds for activity for that species. This method was developed initially for hours of activity in lizards, but it can be applied for any relevant temperature thresholds, like the limits of the thermal neutral zone in mammals or temperature ranges important for seed or egg development.

```{r, eval = FALSE}


# Let's create a function for the Sinervo method
# tmax is the maximum temperature at a location
# tmin is the minimum temperature at a location
# tlwr is the lower temperature threshold for activity
# tupr is the upper temperature threshold for activity
# res is the time resolution, i. e. how many parts of hours are being counted. If res = 3, hours of activity will be counted from 20 to 20 minutes (this will greatly affect the speed of the calculation).

SinervoHA <- function(tmax, tmin, tlwr, tupr, res) {
  
  s0 <- 1:res
  h0 <- 1:24
  
  s <- expand.grid(s0, h0)[[1]]
  h <- expand.grid(s0, h0)[[2]]
  
  day_temps <-
  ((tmax - tmin)/2 * sin((pi/12) * (h + (s/res)) - 3 * (pi/4))) + (tmax + tmin)/2
  
  sum(ifelse(day_temps > tlwr & day_temps < tupr, 1/res, 0))
}

# We can vectorize the function using function Vectorize

SinervoHA_vectorized <- Vectorize(SinervoHA)

SinervoHA(tmax = c(30, 40, 35), tmin = c(10, 20, 15), tlwr = 20, tupr = 30, res = 3)
SinervoHA_vectorized(tmax = c(30, 40, 35), tmin = c(20, 30, 25), tlwr = 20, tupr = 30, res = 3)

values(args_stack$tmax)

Fulanus_present_year_summaries_scaled <- Fulanus_present_year_summaries

Fulanus_present_year_summaries_scaled$tmax_average_year <- Fulanus_present_year_summaries$tmax_average_year/10

Fulanus_present_year_summaries_scaled$tmin_average_year <- Fulanus_present_year_summaries$tmin_average_year/10

ha_sinervo_raster <- 
transform_rasters(raster_stack = Fulanus_present_year_summaries_scaled, 
                  FUN_qlist = qlist(SinervoHA_vectorized(tmax = tmax[[1]], tmin = tmin[[1]],  tlwr = 20, tupr = 30, res = 3)))

plot(ha_sinervo_raster)
```

